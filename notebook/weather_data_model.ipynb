{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16900 entries, 0 to 16899\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Timestamp            16900 non-null  int64  \n",
      " 1   Temperature          16900 non-null  float64\n",
      " 2   Feels Like           16900 non-null  float64\n",
      " 3   Temp Min             16900 non-null  float64\n",
      " 4   Temp Max             16900 non-null  float64\n",
      " 5   Pressure             16900 non-null  int64  \n",
      " 6   Humidity             16900 non-null  int64  \n",
      " 7   Weather Description  16900 non-null  object \n",
      " 8   Wind Speed           16900 non-null  float64\n",
      " 9   Wind Degree          16900 non-null  int64  \n",
      " 10  City                 16900 non-null  object \n",
      "dtypes: float64(5), int64(4), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Feels Like</th>\n",
       "      <th>Temp Min</th>\n",
       "      <th>Temp Max</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Weather Description</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Degree</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1696093200</td>\n",
       "      <td>289.62</td>\n",
       "      <td>289.59</td>\n",
       "      <td>288.05</td>\n",
       "      <td>290.84</td>\n",
       "      <td>1022</td>\n",
       "      <td>87</td>\n",
       "      <td>light intensity drizzle</td>\n",
       "      <td>6.26</td>\n",
       "      <td>360</td>\n",
       "      <td>United States-New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1696096800</td>\n",
       "      <td>290.65</td>\n",
       "      <td>290.62</td>\n",
       "      <td>289.03</td>\n",
       "      <td>292.21</td>\n",
       "      <td>1022</td>\n",
       "      <td>83</td>\n",
       "      <td>light intensity drizzle</td>\n",
       "      <td>5.36</td>\n",
       "      <td>16</td>\n",
       "      <td>United States-New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1696100400</td>\n",
       "      <td>291.75</td>\n",
       "      <td>291.70</td>\n",
       "      <td>289.79</td>\n",
       "      <td>294.18</td>\n",
       "      <td>1021</td>\n",
       "      <td>78</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>6.71</td>\n",
       "      <td>27</td>\n",
       "      <td>United States-New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1696104000</td>\n",
       "      <td>291.97</td>\n",
       "      <td>291.92</td>\n",
       "      <td>289.90</td>\n",
       "      <td>294.46</td>\n",
       "      <td>1021</td>\n",
       "      <td>77</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>4.47</td>\n",
       "      <td>34</td>\n",
       "      <td>United States-New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1696107600</td>\n",
       "      <td>291.78</td>\n",
       "      <td>291.74</td>\n",
       "      <td>290.08</td>\n",
       "      <td>293.48</td>\n",
       "      <td>1022</td>\n",
       "      <td>78</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>5.14</td>\n",
       "      <td>40</td>\n",
       "      <td>United States-New York City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp  Temperature  Feels Like  Temp Min  Temp Max  Pressure  \\\n",
       "0  1696093200       289.62      289.59    288.05    290.84      1022   \n",
       "1  1696096800       290.65      290.62    289.03    292.21      1022   \n",
       "2  1696100400       291.75      291.70    289.79    294.18      1021   \n",
       "3  1696104000       291.97      291.92    289.90    294.46      1021   \n",
       "4  1696107600       291.78      291.74    290.08    293.48      1022   \n",
       "\n",
       "   Humidity      Weather Description  Wind Speed  Wind Degree  \\\n",
       "0        87  light intensity drizzle        6.26          360   \n",
       "1        83  light intensity drizzle        5.36           16   \n",
       "2        78          overcast clouds        6.71           27   \n",
       "3        77          overcast clouds        4.47           34   \n",
       "4        78          overcast clouds        5.14           40   \n",
       "\n",
       "                          City  \n",
       "0  United States-New York City  \n",
       "1  United States-New York City  \n",
       "2  United States-New York City  \n",
       "3  United States-New York City  \n",
       "4  United States-New York City  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/weather_data_combined.csv\")\n",
    "df.info()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "df['Timestamp'] = df['Timestamp'].astype('int64')/1e9\n",
    "lb = LabelEncoder()\n",
    "df['Weather Description'] = lb.fit_transform(df['Weather Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df.drop(['Weather Description', 'City', 'Timestamp'], axis=1)\n",
    "y = df['Weather Description']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5890532544378698\n",
      "Precision: 0.5555644075478618\n",
      "Recall: 0.5890532544378698\n",
      "F1 Score: 0.5479039686679893\n",
      "Confusion Matrix: \n",
      "[[ 161  182    0   20    1    2    0    0    0    0    9    0   48   23\n",
      "     1    0    0    0    0]\n",
      " [  45 1451    0   61    1    3    0    0    0    0   12    0   20   17\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0]\n",
      " [  40  280    0   92    1    3    0    0    0    0    1    0   12   25\n",
      "     0    0    0    0    0]\n",
      " [   1   24    0    1   10    1    0    0    0    0    8    0    1    1\n",
      "     0    1    0    0    0]\n",
      " [   4   27    0    4    0   13    0    0    0    0    2    0    1    2\n",
      "     0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    1    1    0\n",
      "     0    0    0    0    0]\n",
      " [   1    1    0    0    0    0    0    1    0    0    1    0    4    0\n",
      "     0    0    0    0    0]\n",
      " [   7    2    0    0    0    0    0    0   18    0    3    0    7    2\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   6   30    0    2    1    1    0    0    0    0   49    0    9    0\n",
      "     0    0    0    0    0]\n",
      " [   3    6    0    0    0    0    0    0    1    0    2    2    6    0\n",
      "     0    0    0    0    0]\n",
      " [  48   95    0    6    0    2    0    0    3    0    9    2  139    6\n",
      "     0    0    1    0    0]\n",
      " [  34  130    0   23    1    1    0    0    1    0    1    1   14   49\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    8    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    2    0    0    0]\n",
      " [   5    3    0    0    0    0    0    0    0    0    1    2    2    1\n",
      "     0    0    4    0    0]\n",
      " [   0    0    0    0    0    0    1    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix: \\n{cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.13      0.20       447\n",
      "           1       0.52      0.97      0.68      1610\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00       454\n",
      "           5       0.00      0.00      0.00        48\n",
      "           6       0.00      0.00      0.00        53\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         8\n",
      "          10       0.50      0.03      0.05        39\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.36      0.09      0.15        98\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.32      0.20      0.24       311\n",
      "          15       0.00      0.00      0.00       255\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00        10\n",
      "          18       0.00      0.00      0.00        18\n",
      "          19       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      3380\n",
      "   macro avg       0.11      0.07      0.07      3380\n",
      "weighted avg       0.35      0.50      0.38      3380\n",
      "\n",
      "Accuracy: 0.5011834319526627\n",
      "Precision: 0.3462081186866278\n",
      "Recall: 0.5011834319526627\n",
      "F1 Score: 0.37560502911342913\n",
      "Confusion Matrix: \n",
      "[[  58  357    0    0    0    0    0    0    0    0    2    0   30    0\n",
      "     0    0    0    0    0]\n",
      " [  25 1564    0    0    0    0    0    0    0    0    2    0   19    0\n",
      "     0    0    0    0    0]\n",
      " [   0    2    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [  19  421    0    0    0    0    0    0    0    0    0    0   14    0\n",
      "     0    0    0    0    0]\n",
      " [   0   44    0    0    0    0    0    0    0    0    4    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   6   44    0    0    0    0    0    0    0    0    1    0    2    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    2    0\n",
      "     0    0    0    0    0]\n",
      " [   1    3    0    0    0    0    0    0    0    0    0    0    4    0\n",
      "     0    0    0    0    0]\n",
      " [   1   25    0    0    0    0    0    0    1    0    1    0   11    0\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0   65    0    0    0    0    0    0    0    0    9    0   24    0\n",
      "     0    0    0    0    0]\n",
      " [   0    9    0    0    0    0    0    0    0    0    0    0   11    0\n",
      "     0    0    0    0    0]\n",
      " [   9  237    0    0    0    0    0    0    0    0    3    0   62    0\n",
      "     0    0    0    0    0]\n",
      " [  17  224    0    0    0    0    0    0    1    0    1    0   12    0\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    9    0    0    0    0    0    0    0    0    0    0    1    0\n",
      "     0    0    0    0    0]\n",
      " [   7    6    0    0    0    0    0    0    0    0    1    0    4    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    1    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix: \\n{cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics (KNN):\n",
      "   Accuracy  Precision    Recall  F1 Score\n",
      "0  0.495858   0.447301  0.495858   0.45792\n",
      "\n",
      "Confusion Matrix (KNN):\n",
      "     0     1   3   4   5   6   7   8   10  11  12  13  14  15  16  17  18  19  \\\n",
      "0   132   196   0  48   3   4   0   0   1   0   9   0  42  12   0   0   0   0   \n",
      "1   137  1293   0  89   7   7   0   0   1   0   8   0  36  30   0   2   0   0   \n",
      "3     0     1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   \n",
      "4    55   271   0  88   2   7   0   0   0   0   4   0  12  15   0   0   0   0   \n",
      "5     5    23   0   1   8   1   0   0   1   0   7   0   2   0   0   0   0   0   \n",
      "6     5    26   0   7   0   8   0   0   0   0   3   0   4   0   0   0   0   0   \n",
      "7     1     0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   \n",
      "8     2     4   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   \n",
      "10    6     8   0   2   0   0   0   0  14   0   2   0   4   3   0   0   0   0   \n",
      "11    0     1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "12   12    35   0   3   3   2   0   0   2   0  26   2  12   1   0   0   0   0   \n",
      "13    6     5   0   0   0   0   1   0   1   0   2   1   3   1   0   0   0   0   \n",
      "14   64   131   0  18   0   2   0   0   2   0   9   0  80   5   0   0   0   0   \n",
      "15   44   131   0  33   2   2   0   0   1   0   3   0  14  25   0   0   0   0   \n",
      "16    0     1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "17    2     7   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   \n",
      "18    8     2   0   1   0   0   0   0   0   0   1   1   3   2   0   0   0   0   \n",
      "19    0     0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "21    0     1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "    21  \n",
      "0    0  \n",
      "1    0  \n",
      "3    0  \n",
      "4    0  \n",
      "5    0  \n",
      "6    0  \n",
      "7    0  \n",
      "8    0  \n",
      "10   0  \n",
      "11   0  \n",
      "12   0  \n",
      "13   0  \n",
      "14   0  \n",
      "15   0  \n",
      "16   0  \n",
      "17   0  \n",
      "18   0  \n",
      "19   0  \n",
      "21   0  \n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for KNN\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn, average='weighted', zero_division=0)\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='weighted')\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "# Create DataFrame for KNN metrics\n",
    "metrics_df_knn = pd.DataFrame({\n",
    "    'Accuracy': [accuracy_knn],\n",
    "    'Precision': [precision_knn],\n",
    "    'Recall': [recall_knn],\n",
    "    'F1 Score': [f1_knn]\n",
    "})\n",
    "\n",
    "# Print KNN metrics\n",
    "print(\"Metrics (KNN):\")\n",
    "print(metrics_df_knn)\n",
    "\n",
    "# Create DataFrame for KNN confusion matrix\n",
    "cm_df_knn = pd.DataFrame(cm_knn, index=np.unique(y_test), columns=np.unique(y_test))\n",
    "\n",
    "# Print KNN confusion matrix\n",
    "print(\"\\nConfusion Matrix (KNN):\")\n",
    "print(cm_df_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.15      0.22       447\n",
      "           1       0.53      0.97      0.69      1610\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00       454\n",
      "           5       0.00      0.00      0.00        48\n",
      "           6       0.00      0.00      0.00        53\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         8\n",
      "          10       0.85      0.28      0.42        39\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.24      0.12      0.16        98\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.29      0.23      0.26       311\n",
      "          15       0.00      0.00      0.00       255\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00        10\n",
      "          18       0.00      0.00      0.00        18\n",
      "          19       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      3380\n",
      "   macro avg       0.12      0.09      0.09      3380\n",
      "weighted avg       0.35      0.51      0.39      3380\n",
      "\n",
      "Accuracy: 0.5071005917159763\n",
      "Precision: 0.35298969385203816\n",
      "Recall: 0.5071005917159763\n",
      "F1 Score: 0.3893246327941646\n",
      "Confusion Matrix: \n",
      "[[  66  329    0    0    0    0    0    0    0    0    5    0   45    1\n",
      "     1    0    0    0    0]\n",
      " [  26 1554    0    0    0    0    0    0    0    0    7    0   23    0\n",
      "     0    0    0    0    0]\n",
      " [   0    2    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [  20  408    0    0    0    0    0    0    0    0    4    0   22    0\n",
      "     0    0    0    0    0]\n",
      " [   0   42    0    0    0    0    0    0    1    0    4    0    1    0\n",
      "     0    0    0    0    0]\n",
      " [   5   45    0    0    0    0    0    0    0    0    2    0    1    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    3    0\n",
      "     0    0    0    0    0]\n",
      " [   1    4    0    0    0    0    0    0    0    0    0    0    3    0\n",
      "     0    0    0    0    0]\n",
      " [   1    9    0    0    0    0    0    0   11    0    1    0   17    0\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   1   58    0    0    0    0    0    0    0    0   12    0   27    0\n",
      "     0    0    0    0    0]\n",
      " [   0   10    0    0    0    0    0    0    0    0    0    0   10    0\n",
      "     0    0    0    0    0]\n",
      " [   9  222    0    0    0    0    0    0    0    0    9    0   71    0\n",
      "     0    0    0    0    0]\n",
      " [  22  213    0    0    0    0    0    0    1    0    4    0   15    0\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    9    0    0    0    0    0    0    0    0    0    0    1    0\n",
      "     0    0    0    0    0]\n",
      " [   7    5    0    0    0    0    0    0    0    0    1    0    5    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    1    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVM model\n",
    "model = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix: \\n{cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.3559 - accuracy: 0.9584 - val_loss: 0.0194 - val_accuracy: 0.9982\n",
      "Epoch 2/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.0101 - val_accuracy: 0.9982\n",
      "Epoch 3/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9991\n",
      "Epoch 4/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 9.6465e-04 - accuracy: 0.9998 - val_loss: 0.0052 - val_accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.6470e-04 - accuracy: 0.9999 - val_loss: 0.0055 - val_accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.7101e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.2012e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9997\n",
      "Epoch 9/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.8075e-05 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.7475e-05 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9997\n",
      "106/106 [==============================] - 0s 418us/step - loss: 0.0058 - accuracy: 0.9997\n",
      "Test Loss: 0.0058\n",
      "Test Accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a 'text' column and a 'weather' column in your DataFrame\n",
    "X_text = df['Weather Description'].astype(str).values  # Convert to string\n",
    "X_numeric = df[['Temperature', 'Feels Like', 'Temp Min', 'Temp Max', 'Pressure', 'Humidity', 'Wind Speed', 'Wind Degree']]\n",
    "\n",
    "# Convert labels to numerical values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Weather Description'])\n",
    "\n",
    "# Tokenize the text data\n",
    "max_vocab_size = 16000  # Adjust as needed\n",
    "tokenizer = Tokenizer(num_words=max_vocab_size)\n",
    "tokenizer.fit_on_texts(X_text)\n",
    "X_text = tokenizer.texts_to_sequences(X_text)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_len = max(len(seq) for seq in X_text)\n",
    "X_text = pad_sequences(X_text, maxlen=max_len)\n",
    "\n",
    "# Define the preprocessing pipeline for numeric features\n",
    "numeric_features = ['Temperature', 'Feels Like', 'Temp Min', 'Temp Max', 'Pressure', 'Humidity', 'Wind Speed', 'Wind Degree']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine text and numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', Tokenizer(), 'Weather Description'),\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Xây dựng mô hình\n",
    "embedding_dim = 50  # Đặt kích thước của không gian embedding\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "# Biên soạn và huấn luyện mô hình\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Đánh giá mô hình\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Vocab Size: 23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Đọc dữ liệu từ file hoặc nguồn dữ liệu khác\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Xác định cột chứa văn bản\n",
    "text_column = 'Weather Description'\n",
    "\n",
    "# Lấy ra toàn bộ văn bản từ cột\n",
    "all_text = df[text_column].astype(str).values\n",
    "\n",
    "# Khởi tạo Tokenizer và fit trên dữ liệu\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "\n",
    "# Xác định max_vocab_size dựa trên số từ vựng trong tokenizer\n",
    "max_vocab_size = len(tokenizer.word_index)\n",
    "print(\"Max Vocab Size:\", max_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Description\n",
      "clear sky           7981\n",
      "few clouds          2159\n",
      "broken clouds       2130\n",
      "overcast clouds     1601\n",
      "scattered clouds    1411\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu từ file hoặc nguồn dữ liệu khác\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Xác định cột chứa văn bản\n",
    "text_column = 'Weather Description'\n",
    "\n",
    "# Lấy giá trị và số lần xuất hiện của chúng\n",
    "word_counts = df[text_column].value_counts()\n",
    "\n",
    "# In ra một số giá trị đầu tiên\n",
    "print(word_counts.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chia dữ liệu thành tập huấn luyện, tập kiểm tra và tập validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành tập huấn luyện, tập kiểm tra và tập validation\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Xây dựng và huấn luyện mô hình trên tập huấn luyện và đánh giá trên tập validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.9619 - val_loss: 0.0363 - val_accuracy: 0.9941\n",
      "Epoch 2/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.0115 - val_accuracy: 0.9970\n",
      "Epoch 3/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0093 - val_accuracy: 0.9970\n",
      "Epoch 4/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9982\n",
      "Epoch 5/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0064 - val_accuracy: 0.9982\n",
      "Epoch 6/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
      "Epoch 7/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.5785e-04 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "423/423 [==============================] - 1s 3ms/step - loss: 5.8457e-04 - accuracy: 0.9999 - val_loss: 0.0020 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2884e2d90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xây dựng mô hình\n",
    "embedding_dim = 50  \n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "# Biên soạn mô hình\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện và đánh giá trên tập validation\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Điều chỉnh hyperparameters dựa trên đánh giá trên tập validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa vào kết quả huấn luyện và đánh giá trên tập validation, mô hình đã cho thấy hiệu suất rất tốt với độ chính xác lên đến 99.99% trên tập validation. Dưới đây là một số điều nhóm đề xuất để điều chỉnh hyperparameters:\n",
    "\n",
    "**Số lượng epochs:**\n",
    "Dựa vào kết quả, mô hình có vẻ đã hội tụ khá nhanh với số lượng epochs tương đối ít.\n",
    "Nhóm nhận thấy có thể thử giảm số lượng epochs hoặc sử dụng early stopping để ngừng huấn luyện khi không có cải thiện đáng kể."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch size:**\n",
    "Batch size hiện đang là 32. Nhóm dự định thử nghiệm các giá trị khác nhau để xem liệu có sự thay đổi nào không."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kích thước embedding (embedding_dim):**\n",
    "Nhóm em đã sử dụng embedding_dim = 50, có thể thử các giá trị khác nhau, ví dụ như 32, 64, 128, để xem liệu có sự cải thiện nào không."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tăng cường dữ liệu (Data Augmentation):**\n",
    "có thể thử tăng cường dữ liệu để cải thiện khả năng tổng quát hóa của mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout:**\n",
    "Thêm dropout layer để giảm overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning rate:**\n",
    "Thử điều chỉnh learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "423/423 [==============================] - 2s 3ms/step - loss: 0.4174 - accuracy: 0.9231 - val_loss: 0.0411 - val_accuracy: 0.9917\n",
      "Epoch 2/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0170 - accuracy: 0.9979 - val_loss: 0.0170 - val_accuracy: 0.9970\n",
      "Epoch 3/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.0119 - val_accuracy: 0.9970\n",
      "Epoch 4/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0089 - val_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 7/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 6.5079e-04 - accuracy: 0.9999 - val_loss: 9.6153e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 6.1496e-04 - accuracy: 0.9999 - val_loss: 6.8546e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x178edb490>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have a 'text' column and a 'weather' column in your DataFrame\n",
    "X_text = df['Weather Description'].astype(str).values  # Convert to string\n",
    "X_numeric = df[['Temperature', 'Feels Like', 'Temp Min', 'Temp Max', 'Pressure', 'Humidity', 'Wind Speed', 'Wind Degree']]\n",
    "\n",
    "# Convert labels to numerical values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Weather Description'])\n",
    "\n",
    "# Tokenize the text data\n",
    "max_vocab_size = 16000  # Adjust as needed\n",
    "tokenizer = Tokenizer(num_words=max_vocab_size)\n",
    "tokenizer.fit_on_texts(X_text)\n",
    "X_text = tokenizer.texts_to_sequences(X_text)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_len = max(len(seq) for seq in X_text)\n",
    "X_text = pad_sequences(X_text, maxlen=max_len)\n",
    "\n",
    "# Define the preprocessing pipeline for numeric features\n",
    "numeric_features = ['Temperature', 'Feels Like', 'Temp Min', 'Temp Max', 'Pressure', 'Humidity', 'Wind Speed', 'Wind Degree']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine text and numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', Tokenizer(), 'Weather Description'),\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện, tập kiểm tra và tập validation\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Xây dựng mô hình\n",
    "embedding_dim = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Thêm Dropout Layer để giảm overfitting\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "# Biên soạn mô hình\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Sử dụng Early Stopping để ngừng huấn luyện khi không có cải thiện trên tập validation\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện và đánh giá trên tập validation\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Re-train mô hình trên (tập huấn luyện + tập validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 3.0892e-04 - accuracy: 0.9999\n",
      "Epoch 2/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 5.4684e-04 - accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 1.3546e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 1.2934e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 9.3460e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x118e3c890>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epochs = 5  # Thay thế bằng giá trị bạn muốn sử dụng\n",
    "best_batch_size = 32  # Thay thế bằng giá trị bạn muốn sử dụng\n",
    "\n",
    "X_train_final = np.concatenate((X_train, X_val))\n",
    "y_train_final = np.concatenate((y_train, y_val))\n",
    "\n",
    "model.fit(X_train_final, y_train_final, epochs=best_epochs, batch_size=best_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Đánh giá mô hình cuối cùng trên tập kiểm tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 482us/step - loss: 0.0128 - accuracy: 0.9994\n",
      "Test Loss: 0.0128\n",
      "Test Accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
